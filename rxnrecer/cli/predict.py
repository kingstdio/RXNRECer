import sys,os
project_root = os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
sys.path.insert(0, f'{project_root}/')
from rxnrecer.config import config as cfg
import pandas as pd
import numpy as np
import time
from types import SimpleNamespace
import torch
import argparse
from rxnrecer.lib.ml import mlpredict as predRXN
from rxnrecer.lib.llm import qa as llm_qa
from rxnrecer.utils import file_utils as ftool
from rxnrecer.utils import format_utils
from rxnrecer.utils import bio_utils as butils
from tqdm import tqdm
from collections import defaultdict
from rxnrecer.lib.model import mactive as Mactive


def load_model(model_weight_path= cfg.FILE_MOLEL_PRODUCTION_BEST_MODEL):
    mcfg = SimpleNamespace(
    #æ¨¡å‹å‚æ•°
    batch_size=1,
    esm_out_dim=1280,
    gru_h_dim=512,
    att_dim=32,
    dropout_rate=0.2,
    freeze_esm_layers = 32, #å†»ç»“å±‚æ•°,
    output_dimensions=10479,
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu"),
    model_weight_path=model_weight_path,
    dict_path = cfg.FILE_DS_DICT_ID2RXN
    )

    print(f'Use device: {mcfg.device}')
    model = Mactive.BGRU(
        input_dimensions=mcfg.esm_out_dim,
        device = mcfg.device,
        gru_h_size=mcfg.gru_h_dim,
        attention_size=mcfg.att_dim,
        dropout=mcfg.dropout_rate,
        output_dimensions=mcfg.output_dimensions,
        freeze_esm_layers=mcfg.freeze_esm_layers,
    )
    
    return model, mcfg



#region 1. åŠ è½½è®¡ç®—æ•°æ®
def load_data(input_data):
    """
    åŠ è½½è®¡ç®—æ•°æ®ï¼Œæ”¯æŒä¸¤ç§è¾“å…¥æ ¼å¼ï¼š
      1) ä¼ å…¥ FASTA æ–‡ä»¶è·¯å¾„ (str) -> è‡ªåŠ¨è§£æä¸º DataFrame
      2) ç›´æ¥ä¼ å…¥ DataFrame -> å†…å« 'seq' å’Œ 'uniprot_id' åˆ—
    """
    if isinstance(input_data, str):
        # å‡è®¾ä¼ å…¥çš„æ˜¯FASTAæ–‡ä»¶è·¯å¾„
        print(f'Detected input is a FASTA file: {input_data}')
        input_df = ftool.fasta_to_dataframe(fasta_file=input_data)
    elif isinstance(input_data, pd.DataFrame):
        input_df = input_data.copy().reset_index(drop=True)
    else:
        raise ValueError("input_data should be either a path to FASTA or a pandas DataFrame.")
    
    # ç»Ÿä¸€ä¿è¯è¿™äº›åˆ—å­˜åœ¨ï¼ˆè‹¥ä½ çš„ fasta_to_dataframe ä¸­åˆ—åä¸åŒï¼Œéœ€åšç›¸åº”å¤„ç†ï¼‰
    if 'seq' not in input_df.columns:
        raise ValueError("Input DataFrame must contain column 'seq'.")
    if 'uniprot_id' not in input_df.columns:
        raise ValueError("Input DataFrame must contain column 'uniprot_id'.")
    
    return input_df
#endregion 


def format_obj(x, ndigits=6):
    """é€’å½’å¤„ç†å•å…ƒæ ¼å†…å®¹ï¼Œä¿ç•™æµ®ç‚¹æ•°åˆ°æŒ‡å®šå°æ•°ä½"""
    if isinstance(x, (np.floating, float)):
        return round(float(x), ndigits)
    elif isinstance(x, dict):
        return {k: format_obj(v, ndigits) for k, v in x.items()}
    elif isinstance(x, (list, tuple)):
        return [format_obj(v, ndigits) for v in x]
    else:
        return x


#region 2. ä¿å­˜è®¡ç®—ç»“æœ
def save_data(resdf, output_file, output_format='tsv'):
    """
    ä¿å­˜ç»“æœåˆ°æ–‡ä»¶ (TSV/JSON)
    resdf: DataFrame æ ¼å¼çš„ç»“æœ
    output_file: è¾“å‡ºæ–‡ä»¶è·¯å¾„
    output_format: 'tsv' æˆ– 'json'
    """
    resdf = resdf.applymap(lambda x: format_obj(x, 4))
    if output_format == 'tsv':
        resdf.to_csv(output_file, index=False, sep='\t', float_format="%.4f")
    elif output_format == 'json':
        resdf.to_json(output_file, orient='records', indent=4)
    else:
        print(f'Error: Invalid output format {output_format}. Skip saving.')
#endregion 

def step_by_step_prediction(input_data,
                               output_file=None,
                               output_format='tsv',
                               mode='s1',
                               batch_size=100):
    
    if mode == 's3':
        if not cfg.LLM_API_KEY or not cfg.LLM_API_URL:
            print("Error: LLM API key and URL are required for S3 mode!")
            return
    
    input_df = load_data(input_data)
    print(f'Step 1: Preparing input data, loading {len(input_df)} proteins')

    # Step 2: Load predictive model
    print(f'Step 2: Loading predictive model')
    model, mcfg = load_model(model_weight_path=cfg.FILE_MOLEL_PRODUCTION_BEST_MODEL) 
    
        
    res = []
    
    print(f'Step 3: Running prediction on {len(input_df)} proteins')
    # Total number of batches needed (rounding up for incomplete batches)
    batch_num = (len(input_df) + batch_size - 1) // batch_size
    
    for i in tqdm(range(batch_num)):
        # Calculate batch start and end indices
        start = i * batch_size
        end = min((i + 1) * batch_size, len(input_df))  # Ensure the last batch is handled correctly
        
        # Slice the input_data
        batch_data = input_df.iloc[start:end]
        
        # If the batch is non-empty, run prediction
        if not batch_data.empty:
            res_batch = single_batch_run_prediction(batch_data, model=model, mcfg=mcfg, mode=mode)
            res = res + [res_batch]  # Use extend for better performance
    fres = pd.concat(res, axis=0, ignore_index=True)
    
    if output_file is not None:
        print(f'Step 4: Saving results to {output_file} (format={output_format})')
        save_data(fres, output_file, output_format)
        
    fres = fres.drop_duplicates(subset=['input_id'], keep='first')
    # fres = input_df.rename(columns={'uniprot_id':'input_id'}).merge(fres, on='input_id', how='left')
    return fres
    


#region RXNRECer é¢„æµ‹API
def single_batch_run_prediction(input_df, model, mcfg,  mode='s1'):
    """
    å¯¹è¾“å…¥çš„ DataFrame è¿›è¡Œ RXNRECer é¢„æµ‹ï¼Œå¹¶è¿”å›é¢„æµ‹ç»“æœ DataFrameã€‚
    å¯é€‰å‚æ•°:
      - input_df: è¾“å…¥çš„ DataFrameï¼ŒåŒ…å« 'seq' å’Œ 'uniprot_id' åˆ—
      - model: é¢„è®­ç»ƒå¥½çš„æ¨¡å‹
      - mcfg: æ¨¡å‹å‚æ•°é…ç½®
      - featureBank: ç”¨äºè®¡ç®—ç›¸ä¼¼åº¦çš„ç‰¹å¾åº“
      - getEquation: æ˜¯å¦æŸ¥è¯¢å¹¶é™„åŠ æ–¹ç¨‹ä¿¡æ¯ (éœ€è¦ cfg.FILE_DS_RHEA_REACTIONS)
      - Ensemble: æ˜¯å¦ä½¿ç”¨é›†æˆå­¦ä¹ æ–¹æ³•
    """
    input_df = input_df.reset_index(drop=True)
    # RXNRECer-S1
    print('Running RXNRECer-S1 ...')
    res, res_prob = Mactive.predict_sequences(
        model=model,
        sequences=input_df.seq,
        model_weight_path=mcfg.model_weight_path,
        dict_path=mcfg.dict_path,
        batch_size=2,
        device=mcfg.device
    )
    # æ•´åˆé¢„æµ‹ç»“æœ
    # æ³¨æ„ï¼šå¦‚æœæƒ³ä¿ç•™åŸæ¥æ‰€æœ‰åˆ—ï¼Œå¯ä»¥åœ¨ input_df.copy() çš„åŸºç¡€ä¸Šå†æ‹¼ç»“æœ
    res_df_s1 = input_df[['uniprot_id']].reset_index(drop=True).copy()
    res_df_s1['RXNRECer'] = res
    res_df_s1['RXNRECer_with_prob'] = res_prob
    res_df_s1 = res_df_s1.rename(columns={'uniprot_id': 'input_id'})
    
    if mode == 's1':
        #è·å–ååº”è¯¦æƒ…
        rxn_bank = pd.read_feather(cfg.FILE_RHEA_REACTION)
        res_df_s1= butils.get_rxn_details_batch(df_rxns=res_df_s1, rxn_bank=rxn_bank, rxn_id_column='RXNRECer')
        res_df_s1['rxn_details'] = res_df_s1.apply(lambda x: format_utils.format_rxn_output(RXNRECer_with_prob=x.RXNRECer_with_prob, RXN_details=x.RXN_details, mode='s2'), axis=1).tolist()
        res_df_s1 = res_df_s1[['input_id','RXNRECer', 'RXNRECer_with_prob', 'rxn_details']]
        return res_df_s1


    # é›†æˆå­¦ä¹ 
    if mode == 's2':
        print('Running RXNRECer-S2 ...')
        res_df_s2 = get_ensemble(input_df=input_df[['uniprot_id', 'seq']], rxnrecer_df=res_df_s1)#é›†æˆå­¦ä¹ 
        #è·å–ååº”è¯¦æƒ…
        rxn_bank = pd.read_feather(cfg.FILE_RHEA_REACTION)
        res_df_s2= butils.get_rxn_details_batch(df_rxns=res_df_s2, rxn_bank=rxn_bank, rxn_id_column='RXNRECer')
        #æ ¼å¼åŒ–è¾“å‡º
        res_df_s2['rxn_details'] = res_df_s2.apply(lambda x: format_utils.format_rxn_output(RXNRECer_with_prob=x.RXNRECer_with_prob, RXN_details=x.RXN_details, mode='s2'), axis=1).tolist()
        res_df_s2 = res_df_s2[['input_id','RXNRECer', 'RXNRECer_with_prob', 'rxn_details']]
        return res_df_s2
    
    if mode == 's3':
        print('Running RXNRECer-S3 ...')
        res_df_s2 = get_ensemble(input_df=input_df[['uniprot_id', 'seq']], rxnrecer_df=res_df_s1).rename(columns={'RXNRECer': 'RXNRECer-S2'})
        s3_input_df = res_df_s2.merge(res_df_s1[['input_id', 'RXNRECer']].rename(columns={'RXNRECer': 'RXNRECer-S1'}), on='input_id', how='left'
                            ).merge(input_df.rename(columns={'uniprot_id': 'input_id'}), on='input_id', how='left')
        res_df_s3 = llm_qa.batch_chat(res_rxnrecer=s3_input_df, api_key=cfg.LLM_API_KEY, api_url=cfg.LLM_API_URL)
        res_df_s3['rxn_details'] = res_df_s3.apply(lambda x: format_utils.format_rxn_output(RXNRECer_with_prob=x.RXNRECer_with_prob, 
                                                                                            RXNRECER_S3=x['RXNRECER-S3'], 
                                                                                            RXN_details=x.RXN_details, mode='s3'), axis=1)
        res_df_s3 = res_df_s3[['input_id','RXNRECer-S2', 'RXNRECer_with_prob', 'rxn_details']].rename(columns={'RXNRECer-S2': 'RXNRECer'})
        
        return res_df_s3
        
#endregion

#region é›†æˆæ—¶å¤„ç†é…¶å’Œéé…¶æ··åˆæƒ…å†µ
def res_refinement(rxn_prob):
    """
    ç²¾ç‚¼é…¶é¢„æµ‹ååº”ç»“æœï¼Œè§„åˆ™ï¼š
    1. åªæœ‰ä¸€ä¸ªç»“æœï¼ˆæ— è®ºæ˜¯å¦ä¸ºéé…¶ï¼‰ï¼Œç›´æ¥ä¿ç•™
    2. å¦‚æœ '-' æ˜¯æœ€å¤§æ¦‚ç‡é¡¹ï¼Œåˆ™è®¤ä¸ºæ˜¯éé…¶ï¼Œä¿ç•™ '-'
    3. å¦‚æœ '-' æ˜¯æœ€å°æ¦‚ç‡é¡¹æˆ–å±…ä¸­ï¼ˆéæœ€å¤§éæœ€å°ï¼‰ï¼Œåˆ™åˆ é™¤ '-'
    """
    if len(rxn_prob) == 1:
        return cfg.SPLITER.join(rxn_prob.keys()), rxn_prob

    sorted_items = sorted(rxn_prob.items(), key=lambda x: x[1], reverse=True)

    # å¦‚æœ '-' æ˜¯æœ€é«˜æ¦‚ç‡é¡¹ â†’ éé…¶ï¼Œä¿ç•™
    if sorted_items[0][0] == '-':
        return '-', {'-': rxn_prob['-']}

    # å¦‚æœ '-' å­˜åœ¨ä¸”ä¸æ˜¯æœ€é«˜é¡¹ â†’ æ— è®ºå±…ä¸­æˆ–æœ€å°ï¼Œç»Ÿä¸€åˆ é™¤
    if '-' in rxn_prob:
        rxn_prob.pop('-')

    return cfg.SPLITER.join(rxn_prob.keys()), rxn_prob
#endregion


def get_ensemble(input_df, rxnrecer_df):
    """
    èåˆå¤šä¸ªæ–¹æ³•å¯¹è›‹ç™½è¿›è¡Œååº”é¢„æµ‹ï¼Œç”Ÿæˆé›†æˆé¢„æµ‹ç»“æœï¼Œå¹¶å¤„ç†é…¶/éé…¶æ··åˆæƒ…å†µã€‚

    è¾“å…¥å‚æ•°ï¼š
    - input_df: å¾…é¢„æµ‹çš„è›‹ç™½ä¿¡æ¯ï¼ˆDataFrameï¼‰ï¼Œéœ€åŒ…å« 'uniprot_id' åˆ—
    - rxnrecer_df: RXNRECer é¢„æµ‹ç»“æœï¼ˆDataFrameï¼‰ï¼Œéœ€åŒ…å« 'input_id' å’Œ 'RXNRECer_with_prob' åˆ—

    è¿”å›ï¼š
    - res_df: ä»…åŒ…å« input_idã€èåˆé¢„æµ‹å­—ç¬¦ä¸²ï¼ˆRXNRECerï¼‰å’Œæ¦‚ç‡å­—å…¸ï¼ˆRXNRECer_with_probï¼‰çš„ DataFrame
    """

    # è°ƒç”¨å„ä¸ªé¢„æµ‹æ–¹æ³•ï¼ˆMSAã€CatFamã€ECRECerã€T5ã€RXNRECerï¼‰
    res_msa = predRXN.getmsa(df_test=input_df, k=1)
    res_catfam = predRXN.getcatfam(df_test=input_df)
    res_ecrecer = predRXN.getecrecer(df_test=input_df)
    res_t5 = predRXN.getT5(df_test=input_df, topk=1)
    res_rxnrecer = rxnrecer_df.copy().rename(columns={'input_id': 'uniprot_id'})

    # èåˆä¸åŒæ¨¡å‹çš„ç»“æœåˆ°åŒä¸€ DataFrame ä¸­ï¼ˆæŒ‰ uniprot_id å·¦è¿æ¥ï¼‰
    baggingdf = res_rxnrecer.merge(
                    res_msa[['uniprot_id', 'rxn_msa']], on='uniprot_id', how='left'
                ).merge(
                    res_catfam[['uniprot_id', 'rxn_catfam']], on='uniprot_id', how='left'
                ).merge(
                    res_ecrecer[['uniprot_id', 'rxn_ecrecer']], on='uniprot_id', how='left'
                ).merge(
                    res_t5, on='uniprot_id', how='left'
                )

    # æ ‡å‡†åŒ–ç¼ºå¤±é¢„æµ‹ï¼šå°† NO-PREDICTIONã€None å’Œ NaN ç»Ÿä¸€å¤„ç†ä¸º '-'
    baggingdf.replace(['NO-PREDICTION', 'None'], '-', inplace=True)
    baggingdf.fillna('-', inplace=True)

    # è°ƒç”¨é›†æˆæ–¹æ³•è¿›è¡Œèåˆï¼Œè¿”å›æ¯ä¸ªè›‹ç™½å¯¹åº”çš„ååº”é¢„æµ‹å­—å…¸ï¼ˆå«æ¦‚ç‡ï¼‰
    baggingdf['ensemble'] = baggingdf.apply(lambda x: integrateEnsemble(
        esm=x.esm,
        t5=x.t5,
        rxn_recer=x.RXNRECer_with_prob,
        rxn_msa=x.rxn_msa,
        rxn_catfam=x.rxn_catfam,
        rxn_ecrecer=x.rxn_ecrecer
    ), axis=1)

    # æå–èåˆç»“æœä¸ºä¸¤åˆ—ï¼š
    # - RXNRECerï¼šæ‹¼æ¥ reaction idsï¼ˆå­—ç¬¦ä¸²ï¼‰
    # - RXNRECer_with_probï¼šåŸå§‹èåˆå­—å…¸
    baggingdf['RXNRECer_with_prob'] = baggingdf['ensemble']
    baggingdf['RXNRECer'] = baggingdf['ensemble'].apply(lambda x: cfg.SPLITER.join(x.keys()))

    # æ¢å¤ input_id å‘½åä»¥ä¾¿ä¸å¤–éƒ¨ä¿æŒä¸€è‡´
    baggingdf.rename(columns={'uniprot_id': 'input_id'}, inplace=True)

    # ä»…ä¿ç•™éœ€è¦è¾“å‡ºçš„å­—æ®µ
    res_df = baggingdf[['input_id', 'RXNRECer', 'RXNRECer_with_prob']].copy()

    #å¯¹é…¶/éé…¶æ··åˆæƒ…å†µè¿›è¡Œæ¸…æ´—ï¼ˆå»é™¤æ— æ•ˆæˆ–å†²çªçš„ '-' æ ‡ç­¾ï¼‰
    res_df[['RXNRECer', 'RXNRECer_with_prob']] = res_df.apply(
        lambda row: pd.Series(res_refinement(dict(row['RXNRECer_with_prob']))),
        axis=1
    )


    return res_df
    

def integrateEnsemble(esm, t5, rxn_recer, rxn_msa, rxn_catfam, rxn_ecrecer):
    """
    æ•´åˆä¸åŒæ¥æºçš„ RHEA ID æ¦‚ç‡ï¼Œä¼˜å…ˆä¿ç•™è¾ƒé«˜çš„æ¦‚ç‡å€¼ï¼Œå¹¶å¯¹å•ä¸ª RHEA ID è¿›è¡Œå½’å¹¶ã€‚
    
    å‚æ•°:
        esm: åŒ…å« (RHEA_IDs, æ¦‚ç‡) çš„å…ƒç»„åˆ—è¡¨ï¼Œè¿™é‡Œå–ç¬¬ä¸€ä¸ªå…ƒç´ 
        t5: åŒ…å« (RHEA_IDs, æ¦‚ç‡) çš„å…ƒç»„åˆ—è¡¨ï¼Œè¿™é‡Œå–ç¬¬ä¸€ä¸ªå…ƒç´ 
        rxn_recer: å­—å…¸ï¼Œé”®ä¸º RHEA_IDï¼Œå€¼ä¸ºå¯¹åº”çš„æ¦‚ç‡
        rxn_msa: å­—ç¬¦ä¸²ï¼ŒMSA æ–¹æ³•äº§ç”Ÿçš„ RHEA IDï¼ˆå¯èƒ½åŒ…å«å¤šä¸ªï¼Œç”¨åˆ†å·åˆ†éš”ï¼‰
        rxn_catfam: å­—ç¬¦ä¸²ï¼Œåˆ†ç±»å®¶æ—æ–¹æ³•äº§ç”Ÿçš„ RHEA IDï¼ˆå¯èƒ½åŒ…å«å¤šä¸ªï¼Œç”¨åˆ†å·åˆ†éš”ï¼‰
        rxn_ecrecer: å­—ç¬¦ä¸²ï¼ŒEC æ–¹æ³•äº§ç”Ÿçš„ RHEA IDï¼ˆå¯èƒ½åŒ…å«å¤šä¸ªï¼Œç”¨åˆ†å·åˆ†éš”ï¼‰
    
    è¿”å›:
        dict: ä»¥å•ä¸ª RHEA ID ä¸ºé”®ï¼Œå¯¹åº”æœ€å¤§æ¦‚ç‡ä¸ºå€¼çš„å­—å…¸ï¼ŒæŒ‰æ¦‚ç‡é™åºæ’åº
    """
    # -------------------------------
    # 1. èšåˆ esm ä¸ t5 çš„é¢„æµ‹ç»“æœ
    # -------------------------------
    # ä½¿ç”¨ defaultdict(list) å°†åŒä¸€ç»„ï¼ˆå¯èƒ½åŒ…å«å¤šä¸ª RHEA IDï¼Œä»¥åˆ†å·åˆ†éš”ï¼‰çš„æ¦‚ç‡æ”¶é›†åœ¨ä¸€èµ·
    aggregated = defaultdict(list)
    for prediction in (esm[0], t5[0]):
        # å¦‚æœ RHEA ID ä¸º Noneï¼Œåˆ™æ›¿æ¢ä¸º '-' ä»¥ä¿æŒä¸€è‡´æ€§
        rhea_ids = prediction[0] if prediction[0] is not None else '-'
        aggregated[rhea_ids].append(prediction[1])
    
    # -------------------------------
    # 2. æ·»åŠ  rxn_recer çš„é¢„æµ‹ç»“æœ
    # -------------------------------
    # åŒæ ·ç¡®ä¿ None æ›¿æ¢ä¸º '-'
    for rhea_id, prob in rxn_recer.items():
        key = rhea_id if rhea_id is not None else '-'
        aggregated[key].append(prob)
    
    # -------------------------------
    # 3. è®¡ç®—æ¯ç»„ RHEA ID çš„æœ€é«˜æ¦‚ç‡
    # -------------------------------
    # aggregated çš„é”®å¯èƒ½åŒ…å«å¤šä¸ª RHEA IDï¼ˆå¦‚ "ID1;ID2"ï¼‰ï¼Œæ­¤å¤„å¯¹æ¯ç»„å–æœ€å¤§æ¦‚ç‡
    group_max_prob = {group: max(probs) for group, probs in aggregated.items()}
    
    # -------------------------------
    # 4. å°† RHEA ID ç»„æ‹†åˆ†æˆå•ä¸ª RHEA IDï¼Œå¹¶ä¿ç•™è¾ƒé«˜æ¦‚ç‡
    # -------------------------------
    direct_prob = {}
    for group, prob in group_max_prob.items():
        # æ‹†åˆ†å¯èƒ½ç”±åˆ†å·è¿æ¥çš„å¤šä¸ª RHEA ID
        for rhea_id in group.split(';'):
            # å¦‚æœåŒä¸€ RHEA ID æ¥è‡ªå¤šä¸ªç»„ï¼Œä¿ç•™æ¦‚ç‡è¾ƒå¤§çš„é‚£ä¸ª
            direct_prob[rhea_id] = max(direct_prob.get(rhea_id, 0), prob)
    
    # -------------------------------
    # 5. æ„å»º EC æ–¹æ³•æ‰‹åŠ¨æ·»åŠ çš„ RHEA ID å­—å…¸
    # -------------------------------
    # å°† rxn_msa, rxn_catfam, rxn_ecrecer ä¸‰ä¸ªå­—ç¬¦ä¸²æ‹¼æ¥åï¼Œä»¥åˆ†å·æ‹†åˆ†ï¼Œå¾—åˆ°å”¯ä¸€çš„ RHEA ID é›†åˆ
    ec_ids = set(f"{rxn_msa};{rxn_catfam};{rxn_ecrecer}".split(';'))
    # å¯¹æ¯ä¸ª EC æ–¹æ³•äº§ç”Ÿçš„ RHEA ID èµ‹äºˆå›ºå®šæ¦‚ç‡ 0.7777
    ec_prob = {rhea_id: 0.7777 for rhea_id in ec_ids}
    
    # -------------------------------
    # 6. åˆå¹¶æ¥è‡ª direct_prob ä¸ ec_prob çš„ç»“æœ
    # -------------------------------
    # å¯¹äºç›¸åŒçš„ RHEA IDï¼Œå–ä¸¤è¾¹æ¦‚ç‡ä¸­çš„è¾ƒå¤§å€¼
    merged_probs = {}
    for mapping in (ec_prob, direct_prob):
        for rhea_id, prob in mapping.items():
            merged_probs[rhea_id] = max(merged_probs.get(rhea_id, 0), prob)
    
    # -------------------------------
    # 7. æŒ‰æ¦‚ç‡é™åºæ’åºå¹¶è¿”å›ç»“æœ
    # -------------------------------
    sorted_result = dict(sorted(merged_probs.items(), key=lambda item: item[1], reverse=True))
    return sorted_result

    

def main():
    """Main function for command line interface"""
    start_time = time.perf_counter()
    
    # ä½¿ç”¨argparseæ¨¡å—è§£æè¾“å…¥å’Œè¾“å‡ºæ–‡ä»¶è·¯å¾„
    parser = argparse.ArgumentParser(
        description='RXNRECer: A deep learning-based tool for predicting enzyme-catalyzed reactions from protein sequences.',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Examples:
  # Basic S1 prediction with TSV output
  rxnrecer -i input.fasta -o output.tsv -m s1
  
  # S2 prediction with JSON output
  rxnrecer -i input.fasta -o output.json -m s2 -f json
  
  # S3 prediction with custom batch size
  rxnrecer -i input.fasta -o output.tsv -m s3 -b 50
  
  # Use default output path (temp directory)
  rxnrecer -i input.fasta -m s1
        """
    )
    
    parser.add_argument('-i', '--input_fasta', 
                       type=str, 
                       help='Path to input FASTA file (required)')
    parser.add_argument('-o', '--output_file', 
                       type=str, 
                       default=f'{cfg.TEMP_DIR}res_sample10.tsv', 
                       help='Path to output file (default: temp/res_sample10.tsv)')
    parser.add_argument('-f', '--format', 
                       type=str, 
                       choices=['tsv', 'json'], 
                       default='tsv', 
                       help='Output format: tsv or json (default: tsv)')
    parser.add_argument('-m', '--mode', 
                       type=str, 
                       choices=['s1', 's2', 's3'], 
                       default='s1', 
                       help='Prediction mode: s1 (basic), s2 (detailed), s3 (LLM reasoning) (default: s1)')
    parser.add_argument('-b', '--batch_size', 
                       type=int, 
                       default=100, 
                       help='Batch size for processing (default: 100)')
    parser.add_argument('-v', '--version', 
                       action='version', 
                       version='RXNRECer 1.0.0')
    
    # å¦‚æœæ²¡æœ‰æä¾›ä»»ä½•å‚æ•°ï¼Œæ˜¾ç¤ºå¸®åŠ©
    if len(sys.argv) == 1:
        parser.print_help()
        return
    
    args = parser.parse_args()
    
    # æ£€æŸ¥å¿…éœ€å‚æ•°
    if not args.input_fasta:
        print("Error: Input FASTA file is required!")
        print("Use -i or --input_fasta to specify the input file.")
        print("Use -h or --help for more information.")
        return
    
    # æ£€æŸ¥è¾“å…¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not os.path.exists(args.input_fasta):
        print(f"Error: Input file '{args.input_fasta}' does not exist!")
        return
    
    # åˆ›å»ºè¾“å‡ºç›®å½•ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
    output_dir = os.path.dirname(args.output_file)
    if output_dir and not os.path.exists(output_dir):
        os.makedirs(output_dir)
    
    print(f"RXNRECer v1.0.0 - Enzyme Reaction Prediction")
    print(f"Input file: {args.input_fasta}")
    print(f"Output file: {args.output_file}")
    print(f"Output format: {args.format}")
    print(f"Prediction mode: {args.mode}")
    print(f"Batch size: {args.batch_size}")
    print("-" * 50)
    
    
    if args.mode == 's3':
        if not cfg.LLM_API_KEY or not cfg.LLM_API_URL:
            print("Error: LLM API key and URL are required for S3 mode!")
            return
    
    try:
        res = step_by_step_prediction(
            input_data=args.input_fasta, 
            output_file=args.output_file, 
            output_format=args.format,  
            mode=args.mode, 
            batch_size=args.batch_size
        )
        
        end_time = time.perf_counter()
        elapsed_time = end_time - start_time
        
        print(f"\nâœ… Prediction completed successfully!")
        print(f"â±ï¸  Total time: {elapsed_time:.2f} seconds")
        print(f"ğŸ“ Results saved to: {args.output_file}")
        
    except Exception as e:
        print(f"\nâŒ Error during prediction: {str(e)}")
        print("Please check your input parameters and try again.")
        return 1
    
    return 0

if __name__ == '__main__':
    main()
    
